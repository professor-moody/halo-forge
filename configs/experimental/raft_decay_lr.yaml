# =============================================================================
# EXPERIMENTAL: RAFT Configuration - Exponential LR Decay Across Cycles
# =============================================================================
#
# ⚠️  EXPERIMENTAL & THEORETICAL
# 
# This configuration has NOT been validated in production runs.
# Implements exponential learning rate decay across RAFT cycles.
#
# Purpose: Test hypothesis that decreasing LR prevents late-cycle degradation.
# Hypothesis: As training distribution narrows, smaller updates preserve
#             diversity and prevent mode collapse.
#
# =============================================================================

# Experiment metadata
experiment:
  name: "exponential_lr_decay"
  description: "RAFT with exponential LR decay (factor 0.85) across cycles"
  hypothesis: "Decreasing LR prevents late-cycle degradation"
  status: "UNTESTED"
  compare_to: "constant_lr_baseline"

# Model configuration
model:
  name: Qwen/Qwen2.5-Coder-7B
  trust_remote_code: true
  attn_implementation: eager

# Data paths
data:
  prompts: data/rlvr/mbpp_train_prompts.jsonl
  tests: data/rlvr/mbpp_train_full.jsonl

# RAFT configuration
raft:
  num_cycles: 5
  samples_per_prompt: 8
  temperature: 0.7
  top_p: 0.95
  
  # Filtering
  reward_threshold: 0.5
  keep_top_percent: 1.0

# =============================================================================
# LEARNING RATE CONFIGURATION
# =============================================================================
# EXPONENTIAL DECAY across cycles
#
# Formula: lr(cycle) = base_lr * (decay_factor ^ (cycle - 1))
#
# With base_lr=5e-5 and decay=0.85:
#   Cycle 1: 5.00e-5
#   Cycle 2: 4.25e-5
#   Cycle 3: 3.61e-5
#   Cycle 4: 3.07e-5
#   Cycle 5: 2.61e-5
#
# THEORETICAL RATIONALE:
# - Early cycles: Higher LR for faster learning from diverse samples
# - Later cycles: Lower LR for careful refinement of narrower distribution
# - 0.85 decay is moderate; more aggressive (0.7) or conservative (0.95) may work

training:
  # Base learning rate (cycle 1)
  base_learning_rate: 5e-5
  
  # Decay factor per cycle
  lr_decay_factor: 0.85
  
  # Explicit schedule (computed from above, for reference)
  # Implementation should compute dynamically, but explicit values useful for debugging
  learning_rate_schedule:
    cycle_1: 5.00e-5
    cycle_2: 4.25e-5
    cycle_3: 3.61e-5
    cycle_4: 3.07e-5
    cycle_5: 2.61e-5
  
  # Within-cycle schedule
  warmup_steps: 10
  lr_scheduler_type: linear
  
  # Training parameters
  epochs_per_cycle: 1
  batch_size: 2
  gradient_accumulation_steps: 16
  
  # Regularization
  weight_decay: 0.01
  max_grad_norm: 0.3
  
  # Strix Halo requirements
  dataloader_num_workers: 0
  dataloader_pin_memory: false
  bf16: true
  gradient_checkpointing: true

# LoRA configuration
lora:
  r: 16
  alpha: 32
  dropout: 0.05
  target_modules:
    - q_proj
    - k_proj
    - v_proj
    - o_proj
    - gate_proj
    - up_proj
    - down_proj

# Verifier configuration
verifier:
  type: rlvr_pytest
  dataset_type: mbpp
  timeout: 30
  reward_partial: true

# Checkpointing
checkpointing:
  save_every_cycle: true
  output_dir: models/experiments/exponential_decay
  save_total_limit: 6

# Logging
logging:
  log_every_n_steps: 5
  metrics_to_track:
    - train_loss
    - gradient_norm
    - verification_rate
    - samples_kept
    - cycle_duration
    - current_learning_rate  # Important: track actual LR per cycle

# =============================================================================
# COMPARISON METRICS
# =============================================================================
#
# Compare against constant_lr_baseline:
# 1. Peak verification rate (which config achieves higher?)
# 2. Cycle of peak performance (does decay delay degradation?)
# 3. Gradient norm patterns (is decay reducing gradient clipping?)
# 4. Output diversity (does decay preserve more variety?)
#
# If exponential decay shows improvement, try:
# - More aggressive decay (0.7) - see raft_aggressive_decay.yaml
# - More conservative decay (0.95)
# =============================================================================
