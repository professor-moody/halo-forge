# =============================================================================
# EXPERIMENTAL: RAFT Configuration - Constant Learning Rate Baseline
# =============================================================================
#
# ⚠️  EXPERIMENTAL & THEORETICAL
# 
# This configuration has NOT been validated in production runs.
# Use as a baseline for comparison against decay strategies.
#
# Purpose: Establish baseline behavior with constant LR across all cycles.
# Hypothesis: Constant LR may cause degradation in later cycles due to
#             distribution narrowing, but provides clean baseline.
#
# =============================================================================

# Experiment metadata
experiment:
  name: "constant_lr_baseline"
  description: "Baseline RAFT with constant learning rate across cycles"
  hypothesis: "Later cycles may degrade without LR decay"
  status: "UNTESTED"

# Model configuration
model:
  name: Qwen/Qwen2.5-Coder-7B
  trust_remote_code: true
  attn_implementation: eager

# Data paths (update for your setup)
data:
  prompts: data/rlvr/mbpp_train_prompts.jsonl
  tests: data/rlvr/mbpp_train_full.jsonl

# RAFT configuration
raft:
  num_cycles: 5
  samples_per_prompt: 8
  temperature: 0.7
  top_p: 0.95
  
  # Filtering strategy
  reward_threshold: 0.5      # Minimum reward to keep
  keep_top_percent: 1.0      # Keep all passing samples (RFT style)

# =============================================================================
# LEARNING RATE CONFIGURATION
# =============================================================================
# CONSTANT LR - Same value across all cycles
# This is the baseline to compare decay strategies against.

training:
  # Constant learning rate across all cycles
  learning_rate: 5e-5        # EXPERIMENTAL: May be too high for later cycles
  
  # Within-cycle schedule
  warmup_steps: 10
  lr_scheduler_type: linear  # Decays to 0 within each cycle
  
  # Training parameters
  epochs_per_cycle: 1
  batch_size: 2
  gradient_accumulation_steps: 16  # Effective batch = 32
  
  # Regularization
  weight_decay: 0.01
  max_grad_norm: 0.3
  
  # Strix Halo requirements
  dataloader_num_workers: 0
  dataloader_pin_memory: false
  bf16: true
  gradient_checkpointing: true

# LoRA configuration
lora:
  r: 16
  alpha: 32
  dropout: 0.05
  target_modules:
    - q_proj
    - k_proj
    - v_proj
    - o_proj
    - gate_proj
    - up_proj
    - down_proj

# Verifier configuration
verifier:
  type: rlvr_pytest
  dataset_type: mbpp
  timeout: 30
  reward_partial: true

# Checkpointing
checkpointing:
  save_every_cycle: true
  output_dir: models/experiments/constant_lr
  save_total_limit: 6  # Keep all cycles for analysis

# Logging
logging:
  log_every_n_steps: 5
  metrics_to_track:
    - train_loss
    - gradient_norm
    - verification_rate
    - samples_kept
    - cycle_duration

# =============================================================================
# EXPECTED OBSERVATIONS
# =============================================================================
# 
# Things to watch for:
# 1. Does verification rate improve in cycles 1-3?
# 2. Does it plateau or degrade in cycles 4-5?
# 3. Are gradients being clipped frequently?
# 4. Does output diversity decrease over cycles?
#
# If degradation observed in later cycles, compare against decay configs.
# =============================================================================
